{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliviachioccariello/NEUR265/blob/main/04_10_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calcium Imaging \n",
        "\n",
        "In this notebook, we'll learn how calcium imaging works, how data are acquired, and how movies taken from microscopes are converted into fluorescent traces that can be correlated with behavior. "
      ],
      "metadata": {
        "id": "9Per9Bw5pygh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##By the end of this notebook, you will be able to:\n",
        "\n",
        "- Plot locations of putative cells (regions of interest, or ROIs) \n",
        "- Extract activity traces from these ROIs\n",
        "- Cluster ROIs according to patterns of activity\n",
        "- Correlate these patterns of activity with specific locations in the brain"
      ],
      "metadata": {
        "id": "DU22TtThqDPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction\n",
        "\n",
        "Calcium imaging is a widely used technique in neuroscience research. Consider that, when recording action potentials from a tetrode or silicon probe, you are likely recording these action potentials from a variety of different \"types\" of neurons. One example of this would be *Sst* interneurons and *Pvalb* interneurons - which are all mixed in together in areas of cortex. A tetrode has no way of differentiating between these different types of neurons. To a tetrode, all action potentials are the same, and it will record action potentials from any neuron that is near it. To get around this problem, scientists engineered a protein, called \"GCaMP\", that fluoresces green (emits green fluorescent protein, or GFP) every time calcium enters a cell:"
      ],
      "metadata": {
        "id": "G2AaDmaXrL7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://drive.google.com/uc?id=1ozU9-MZD2c2ChXShmESv7RPL8oiTiaGs'>"
      ],
      "metadata": {
        "id": "CB9p6RQTsv6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The genetic sequence that codes for GCaMP can be packaged into a virus, and injected into the brain. Remember from our earlier lectures that viruses can be used to target specific \"types\" of cells based on marker genes that those cells express. So, if we wanted to only look at *Pvalb* interneurons, we could make a virus that would only express GCaMP in neurons that also express *Pvalb*. Another advantage of calcium imaging is that we can *where* the neurons we image are located relative to each other - something that is impossible to do with tetrodes. "
      ],
      "metadata": {
        "id": "_e_YE7wYs2_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once GCaMP is expressed in the brain, we need some way of imaging the fluorescence that occurs every time calcium enters the cell. Neuroscientists do this with microscopes - either 2-photon microscopes with \"fixed\" preparations (i.e., cells in a dish, or head-fixed animals):"
      ],
      "metadata": {
        "id": "uHVbxbNftq1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://drive.google.com/uc?id=1y9JvV780k1SCxQQjCP_lKBZHrU6Jf78W'>"
      ],
      "metadata": {
        "id": "ggOCFmdCuXPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or with \"miniscopes\", which are 1-photon microscopes that can be attached to a lens that is surgically implanted into an animal's brain. The advantage of a miniscope is that the animal can move around during imaging, so that cellular responses can be correlated with some kind of behavior of interest:"
      ],
      "metadata": {
        "id": "KeDcVCaSuegH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src = 'https://drive.google.com/uc?id=1W78a2f9eesF3VaGs040rmCH579LUIiIc'>"
      ],
      "metadata": {
        "id": "TORvY6NgvC-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will be analyzing calcium imaging data from a light sheet microscope. These data were taken from zebrafish larvae expressing GCaMP in an area of the brain called the \"pallium\", a part of the telencephalic lobs in fish. We are interested to know if neurons in the pallium respond to a visual stimulus (LED), and if so, where in the pallium these neurons are located. "
      ],
      "metadata": {
        "id": "m8_LhxkjvQI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import relevant modules\n",
        "\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from scipy.cluster.vq import vq, kmeans2\n",
        "import matplotlib.patches as patches\n",
        "from matplotlib import cm\n",
        "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
        "from random import seed"
      ],
      "metadata": {
        "id": "rOA0lCwvxYQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have already isolated ROIs from our raw movie - the traces from these ROIs are stored in a .csv file called <code>zebrafish_traces.csv</code> on our GitHub repo. Import this file as a <code>pandas</code> dataframe called <code>zebrafish_traces</code> below:"
      ],
      "metadata": {
        "id": "jl0l4TqoySYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import traces!\n"
      ],
      "metadata": {
        "id": "fZ4EbLg3ylaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many methods for extracting ROIs from raw imaging movies - all of these methods are time consuming and super computationally intensive! All of these methods extract \"normalized fluorescence intesity\" from movies - basically, the fluorescence emitted from GCaMP with fluorescent \"noise\" (background fluorescence) subracted from it. This background-normalized fluorescent signal is often called \"$\\Delta$F/F\""
      ],
      "metadata": {
        "id": "rRGWYOMIyrSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task:</b> Look at the first five rows of your <code>zebrafish_traces</code> dataframe. What are the columns? What do you think each column contains?"
      ],
      "metadata": {
        "id": "ZE62jMnPz_DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at your dataframe!\n"
      ],
      "metadata": {
        "id": "-YlM7-Tt0g7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should notice that there is a column called \"<code>is_cell</code>\", which contains a boolean indicating whether the extracted trace was identified as a cell or not (the algorithms that extract ROIs from raw images often make mistakes, and human intervention is needed to correctly separate noise from real signal). If we want to plot the traces in this dataframe, we should get rid of the rows that don't contain traces from cells:"
      ],
      "metadata": {
        "id": "HGobeAI_1NM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gettin' rid of noise\n",
        "\n",
        "cells = zebrafish_traces[zebrafish_traces['is_cell'] == 1]"
      ],
      "metadata": {
        "id": "g_n_md8p1qUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To plot our traces, it would be easier also to export all columns that contain fluorescence data from the <code>is_cell</code> column and columns that contain x/y coordinates. Make a new variable below called <code>cells_activity</code> that contains all rows of <code>cells</code>, and columns 1:1201. Use the <code>.iloc</code> method from <code>pandas</code> to index the rows and columns you want:"
      ],
      "metadata": {
        "id": "ZiijWe6412uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put just the fluorescent traces into a new dataframe\n"
      ],
      "metadata": {
        "id": "ft-iDcFo2IIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task:</b> Make a variable, <code>time</code>, that starts at \"0\", ends at the length of the recording session, and has a length equal to the number of samples in your <code>cells_activity</code> dataframe. The length of time between each sample in your <code>cells_activity</code> variable is equal to 3 s. Use this information to find the total length of the recording session, in seconds, and the microscope's frame rate (fps). "
      ],
      "metadata": {
        "id": "lyFjavXt0h-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here!\n"
      ],
      "metadata": {
        "id": "Ary8lm9m3bjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task:</b> Plot the first row of your <code>cells_activity</code> variable in <font color = 'blue'>blue</font>, and the second row of your <code>cells_activity</code> variable in <font color = 'red'>red</font>. Put time on the x-axis. Label your axes. "
      ],
      "metadata": {
        "id": "zfj95d3l3olJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot some traces!\n"
      ],
      "metadata": {
        "id": "Xv_X35jL34Rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"<code>x</code>\" and \"<code>y</code>\" columns of your <code>cells</code> dataframe contain coordinates for each ROI within the original imaging movie. These coordinates are useful for visualizing where each ROI was imaged from within the zebrafish pallium. We could use this information to answer questions like: Are cells with similar patterns of activity located more closely to one another? "
      ],
      "metadata": {
        "id": "KEiWSysS4Dww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task:</b> Create a scatter plot that displays the x and y coordinates from all cells in your <code>cells</code> dataframe."
      ],
      "metadata": {
        "id": "bciBKEnc4c7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a scatter plot!"
      ],
      "metadata": {
        "id": "f89-b3Aj4m8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without seeing an image of the brain from our raw movie, it's hard to interpret the scatter plot above. We can overlay the x/y coordinates on top of such an image to get a better understanding of where each ROI was located in the pallium. To do this, we need to import this image from our GitHub repo:"
      ],
      "metadata": {
        "id": "RG2JgKFe5DUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import a raw image\n",
        "\n",
        "!git clone https://github.com/hallockh/neur_265.git images\n",
        "from PIL import Image\n",
        "img_fname = 'images/zebrafish_image.tif'\n"
      ],
      "metadata": {
        "id": "yqpAfwBE5Usv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also plot the raw traces next to the image. To do this, we'll need to scale our traces to values between \"0\" and \"1\" so that they can all fit together on the same plot. Let's make a quick function that will do this:"
      ],
      "metadata": {
        "id": "y_L68J4J6g9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scalin' traces\n",
        "\n",
        "def norm(f):\n",
        "    return (f - np.min(f))/np.max(f - np.min(f))"
      ],
      "metadata": {
        "id": "sTzJ2LY46niC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's plot our data:"
      ],
      "metadata": {
        "id": "MTegmGJj6vOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "secPerFrame = 3; # time between frames\n",
        "plt.figure(figsize=(18,10))\n",
        "\n",
        "ax1 = plt.subplot(1,2,2)\n",
        "ax2 = plt.subplot(1,2,1)\n",
        "\n",
        "xs,ys = [cells.x, cells.y]\n",
        "# show original data image\n",
        "plt.imshow(io.imread(img_fname))\n",
        "# plot locations of cells as open circles\n",
        "plt.scatter(ys, xs, s=30,facecolors='none',edgecolors='w')\n",
        "\n",
        "# select \"first\" 20 cells\n",
        "cell_ids = range(20)\n",
        "\n",
        "# or select random 20 cells from all the cells, replace=False means that there will be no repetitions\n",
        "#cell_ids = np.random.choice(range(len(cells)), 20, replace=False)\n",
        "\n",
        "for cell_i in range(len(cell_ids)):\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(time, norm(cells_activity.iloc[cell_ids[cell_i],:]) + cell_i ,'k')\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.text(ys.iloc[cell_ids[cell_i]], xs.iloc[cell_ids[cell_i]], cell_i,fontsize=15,color='w',weight='bold')\n",
        "\n",
        "ax1.set_yticks(range(len(cell_ids)))\n",
        "ax1.set_ylabel('Cell ID')\n",
        "ax1.set_xlabel('Time, sec')\n",
        "\n",
        "ax1.set_aspect(np.max(time) / len(cell_ids))\n",
        "ax2.set_aspect(1)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "cb = plt.colorbar( fraction=0.039, pad=0.03);  # magic numbers fraction & pad to set up proper size of the colorbar\n",
        "cb.set_label('Fluorescence, a.u.')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Og6LJsdm6xTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Look at the traces on the right, and see if you can identify some that seem to have similar patterns of activity. Do these traces seem to come from cells (ROIs) that are located in the same area of the pallium?"
      ],
      "metadata": {
        "id": "OPGVtxKq9Pt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "><b>Task:</b> Un-comment the line that makes your <code>cell_ids</code> variable equal to randomly-picked traces, and re-make your plot. Which traces did you get? Do you notice any relationships between function and spatial location in these cells?"
      ],
      "metadata": {
        "id": "TDHNuzEn9fpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From looking at our raw traces, we might notice that it seems like some traces have similar patterns of activity - for example, cells \"3\" and \"7\" seem like they both have irregular patterns of fluorescence across time, while cells \"0\" and \"2\" seem like they have regular \"bursts\" of fluorescence that are equally spaced apart. Instead of relating each individual trace to a spatial location on our image, it might instead be useful to try and cluster traces that have similar patterns of activity together, and see how these clusters map onto our image. To do this, we can use a technique called [\"K-means clustering\"]('https://en.wikipedia.org/wiki/K-means_clustering') - a method that creates *n* clusters based on variance in a dataset, and attempts to assign each datapoint (in this case, each ROI) to a given cluster based on proximity of that datapoint to the cluster's mean. \n",
        "\n",
        "Before we do this, it might be helpful to view all of the ROIs in our dataset as a heatmap to more clearly identify any similar patterns of activity that might exist:"
      ],
      "metadata": {
        "id": "XbnSGEbI-G7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot original traces as a heatmap\n",
        "\n",
        "data_t = np.asarray(cells_activity.iloc[:,:]);\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "ax1 = plt.subplot(1,2,1)\n",
        "plt.imshow(data_t)\n",
        "ax1.set_aspect(4)\n",
        "plt.title('Original traces');"
      ],
      "metadata": {
        "id": "L-MDLxcW_2iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Do you notice any ROIs that seem to have similar patterns of activity? How many clusters of similar ROIs do you think there might be in the data?"
      ],
      "metadata": {
        "id": "XkQTPL3rAAsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now apply K-means clustering to the data, and see what we get:"
      ],
      "metadata": {
        "id": "3wEEiAfzAeNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply K-means clustering\n",
        "\n",
        "data_t = np.asarray(cells_activity.iloc[:,:]);\n",
        "\n",
        "plt.figure(figsize=(14,14))\n",
        "ax1 = plt.subplot(1,2,1)\n",
        "plt.imshow(data_t)\n",
        "ax1.set_aspect(4)\n",
        "plt.title('Original traces');\n",
        "\n",
        "ax2 = plt.subplot(1,2,2)\n",
        "\n",
        "Ks = 5\n",
        "# K-means relies on random number generation, we can fix the seed to have same result each time \n",
        "centroid, labels = kmeans2(data_t, Ks, seed=1111111)\n",
        "\n",
        "# argsort outputs indeces after sorting the argument\n",
        "# so i_labels contains indeces of cells, sorted by corresponding cluster ID\n",
        "i_labels = np.argsort(labels)\n",
        "\n",
        "plt.imshow(data_t[i_labels,:])\n",
        "ax2.set_aspect(4)\n",
        "plt.title('Traces sorted by K-means');\n",
        "\n",
        "cmap = cm.get_cmap('terrain', Ks)\n",
        "\n",
        "# Cosmetic code to create a Rectangle patches to label specific K-cluster\n",
        "Koffset = 0\n",
        "for Ki in range(Ks):\n",
        "    Nk = np.size(np.where(labels == Ki))\n",
        "    # 40 is width of the rectangle\n",
        "    rect = patches.Rectangle((0, Koffset), 50, Nk, linewidth=1, edgecolor='none', facecolor=cmap(Ki))\n",
        "    ax2.text( 10, Koffset + Nk/2, Ki ,color='k', weight='bold')\n",
        "    # Add the patch to the plot\n",
        "    ax2.add_patch(rect)\n",
        "    Koffset += Nk\n",
        "\n",
        "ax2.text(10,-5,'↓ Cluster ID',fontsize=10)\n",
        "\n",
        "    \n",
        "# add subplot labels\n",
        "ax1.text(-200,-10,'A',fontsize=15)\n",
        "ax2.text(-200,-10,'B',fontsize=15)\n",
        "\n",
        "ax1.set_xlabel('Frame')\n",
        "ax2.set_xlabel('Frame')\n",
        "\n",
        "ax1.set_ylabel('Cell')\n",
        "ax2.set_ylabel('Cell')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J8ykI3VIAgfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Notice that we defined the number of clusters that we wanted before applying the algorithm. Do you think that this number of clusters is appropriate? Try re-running the algorithm with 4 clusters, and again with 6. What do you notice?"
      ],
      "metadata": {
        "id": "EaAmg4grA1MT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to know how these clusters might map onto spatial location in the pallium. To do this, we'll need to plot our clusters on top of our zebrafish image."
      ],
      "metadata": {
        "id": "J4qrIoVFBFTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot locations of ROIs color-coded by cluster\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# show original data image\n",
        "# comment it if the image is too busy, but it will require adjusting legend position since imshow flips Y axis\n",
        "plt.imshow(io.imread(img_fname)) # †\n",
        "\n",
        "# use same colormap as rectangles from raster plot\n",
        "# each color represents one cluster\n",
        "plt.scatter(ys, xs, 100, c = labels, cmap=cmap, edgecolors='k', linewidth=1)\n",
        "\n",
        "# remove ticks\n",
        "ax = plt.gca();\n",
        "ax.set_xticklabels([])\n",
        "ax.set_yticklabels([])\n",
        "\n",
        "# add cluster legend\n",
        "for Ki in range(Ks):\n",
        "    # create rectangle\n",
        "    rect = patches.Rectangle((5, Ki*6+8), 10, 5, linewidth=1, edgecolor='k', facecolor=cmap(Ki))\n",
        "    # add text with cluster number\n",
        "    ax.text( 5+4, Ki*6+8+4, Ki ,color=('w' if Ki==0 else 'k'), weight='bold')\n",
        "    # Note: we use white color for cluster 0 due to better visibility\n",
        "    # see https://en.wikipedia.org/wiki/%3F:#Python for syntax\n",
        "\n",
        "    # Add the patch to the plot\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "# uncomment if you are not using imshow() above (†)\n",
        "# plt.gca().invert_yaxis()\n",
        "\n",
        "ax.text(1, 4, 'Clusters:', color='w', weight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Hn7HO22BTmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Does there seem to be any anatomical organization to the clusters? How does each cluster map to distinct areas of the zebrafish brain?"
      ],
      "metadata": {
        "id": "dZWuIYlDBaj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also plot the average fluorescent trace from each cluster below:"
      ],
      "metadata": {
        "id": "wYbvvJJyC7yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = plt.figure(figsize=(20,5))\n",
        "plt.subplot(121)\n",
        "\n",
        "for Ki in range(0,Ks):\n",
        "    # find indeces of traces where cluster label equals to Ki\n",
        "    js = np.where(labels == Ki);\n",
        "    # calculate average activity trace for cluster Ki\n",
        "    d  = np.mean(np.squeeze(data_t[js, :]), axis=0);\n",
        "    # normalize so that each trace is between 0 and 1\n",
        "    d  = norm(d);\n",
        "    plt.plot(d+Ki)\n",
        "    \n",
        "p = plt.gca();\n",
        "p.set_ylabel('Cluster ID', fontsize=15)\n",
        "p.set_xlabel('Frame', fontsize=15)\n",
        "p.set_title('Average activity of each cluster', fontsize=20)\n",
        "\n",
        "# add subplot label for figure\n",
        "plt.text(-200,5.5,'A',fontsize=20)\n",
        "\n",
        "\n",
        "plt.subplot(122)\n",
        "\n",
        "K0 = 2;\n",
        "iis = np.where(labels == K0)[0];\n",
        "m = np.mean(data_t[iis,:], 0)\n",
        "s = np.std(data_t[iis,:], 0)\n",
        "ts = range(0,1200)\n",
        "plt.plot(m,'-k')\n",
        "# create fill between mean-std and mean+std, fill with grey color\n",
        "plt.fill_between(ts, m-s, m+s, alpha=0.4, color=(0.1,0.1,0.1))\n",
        "p = plt.gca();\n",
        "\n",
        "# Here we use LaTeX symbol for plus/minus sign\n",
        "p.set_title('Average activity of Cluster #' +str(K0)+  ' (mean $\\pm$ std)', fontsize=20)\n",
        "p.set_xlabel('Frame', fontsize=15)\n",
        "p.set_ylabel('Activity, a.u.', fontsize=15)\n",
        "\n",
        "p.legend(('mean','std'), fontsize=15)\n",
        "plt.text(-200,0.8,'B',fontsize=20)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "t8C8oEbXC_DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems like these 5 clusters do a good job of representing the variation in activity across all ROIs. \n",
        "\n",
        "K-means clustering is not the only way to perform splitting of the data into separate groups of similar activity. The embedding technique tSNE is a popular tool to visualize multidimensional data, and often applied to segmented neurons activity. For example, it can provide insight into co-activity of neurons primarily tuned to different external stimuli. "
      ],
      "metadata": {
        "id": "4jFX4FlGDKPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "# perform t-SNE dimentionality reduction\n",
        "# t-SNE relies or random number generation, so we fix random_state to have same result each time we run the code\n",
        "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random', random_state=1113).fit_transform(data_t)\n",
        "\n",
        "plt.figure(figsize=(14,12))\n",
        "\n",
        "# plot t-SNE embedding in two-dimentional space\n",
        "ax_tsne = plt.subplot(221)\n",
        "plt.plot(X_embedded[:,0], X_embedded[:,1],'*')\n",
        "plt.text(-20,9,'A',fontsize=20)\n",
        "\n",
        "# format aspect ratio and axis labels\n",
        "ax_tsne.set_aspect(1.5)\n",
        "ax_tsne.set_xlabel('t-SNE_1')\n",
        "ax_tsne.set_ylabel('t-SNE_2')\n",
        "ax_tsne.set_title('t-SNE results')\n",
        "\n",
        "# repeat plotting for further manual thresholding\n",
        "ax_tsne = plt.subplot(222)\n",
        "plt.plot(X_embedded[:,0], X_embedded[:,1],'*')\n",
        "ax_tsne.set_aspect(1.5)\n",
        "ax_tsne.set_xlabel('t-SNE_1')\n",
        "ax_tsne.set_ylabel('t-SNE_2')\n",
        "ax_tsne.set_title('t-SNE results with manual thresholding')\n",
        "plt.text(-20,9,'B',fontsize=20)\n",
        "\n",
        "\n",
        "# manually split all elements by tSNE_1 = -5\n",
        "# np.where returns index of elements that satisfy given condition\n",
        "iis_red = np.where(X_embedded[:,0]<-5);\n",
        "iis_blue = np.where(X_embedded[:,0]>=-5);\n",
        "\n",
        "# label points left to the tSNE_1 = -5 line in red\n",
        "plt.scatter(X_embedded[iis_red,0], X_embedded[iis_red,1],80, 'r', marker='o')\n",
        "# demarcation line\n",
        "plt.plot([-5, -5],[-8, 8],'--k')\n",
        "\n",
        "# plot traces of all \"red\" cells\n",
        "ax1 = plt.subplot(223)\n",
        "plt.imshow(data_t[np.asarray(iis_red)[0],:], vmin=0,vmax=.50)\n",
        "ax1.set_aspect(20)\n",
        "ax1.set_title('Red cells')\n",
        "ax1.set_ylabel('Cell ID')\n",
        "ax1.set_xlabel('Frames')\n",
        "plt.text(-200,-2,'C',fontsize=20)\n",
        "# plot traces of all \"non-red\" cells\n",
        "ax2 = plt.subplot(224)\n",
        "plt.imshow(data_t[np.asarray(iis_blue)[0],:], vmin=0,vmax=.50)\n",
        "ax2.set_aspect(6)\n",
        "ax2.set_title('Blue cells')\n",
        "ax2.set_ylabel('Cell ID')\n",
        "ax2.set_xlabel('Frames')\n",
        "plt.text(-200,-2,'D',fontsize=20)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_8hBHpkTErKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because tSNE and scipy‘s implementation of K-means clustering both use Euclidian distance metric, results of these methods are connected. For each cell we have a “red/non-red” label, as well as K-means clustering cluster identifier. The histogram of these identifiers for each of tSNE groups shows that “red” cells are not overlapped with “non-red” cells in K-means clustering "
      ],
      "metadata": {
        "id": "Q6M9AbSjE--L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare manual segmentation into red/blue cells and K-means clustering from earlier step\n",
        "# Plot historgram of cluster values for red cenns and blue cells\n",
        "plt.hist(labels[iis_blue], bins=range(Ks+1),align='left',rwidth=0.8,facecolor='b')\n",
        "plt.hist(labels[iis_red],  bins=range(Ks+1),align='left',rwidth=0.5,facecolor='r')\n",
        "# Red cells are exclusively present in clusters 0 and 3 \n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_title('Number of red and blue cells per K-means cluster')\n",
        "ax.set_xlabel('Cluster')\n",
        "ax.set_ylabel('Number of cells')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iivmc9R2E_1u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}